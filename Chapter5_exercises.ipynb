{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "np.random.seed(1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Exercises\n",
    "\n",
    "## Conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Using basic statistical properties of the variance, as well as single- variable calculus, derive (5.6). In other words, prove that Î± given by (5.6) does indeed minimize $Var(\\alpha X + (1 - \\alpha)Y)$.\n",
    "\n",
    "We want to minimize:\n",
    "$$\n",
    "Var(\\alpha X + (1 - \\alpha)Y)\n",
    "\\\\\n",
    "= Var(\\alpha X) + Var((1 - \\alpha) Y) + 2 Cov(\\alpha X, (1 - \\alpha) Y)\n",
    "\\\\\n",
    "= \\alpha^2 Var(X) + (1 - \\alpha)^2 Var(Y) + 2 \\alpha (1 - \\alpha) Cov(X, Y)\n",
    "\\\\\n",
    "= \\sigma_X^2 \\alpha^2 + \\sigma_Y^2 (1 - \\alpha)^2 + 2 \\sigma_{XY} (-\\alpha^2 +\n",
    "\\alpha)\n",
    "$$\n",
    "\n",
    "Take the first derivative to find critical points:\n",
    "$$\n",
    "0 = \\frac {d} {d\\alpha} f(\\alpha)\n",
    "\\\\\n",
    "0 = 2 \\sigma_X^2 \\alpha + 2 \\sigma_Y^2 (1 - \\alpha) (-1) + 2 \\sigma_{XY}\n",
    "(-2 \\alpha + 1)\n",
    "\\\\\n",
    "0 = \\sigma_X^2 \\alpha + \\sigma_Y^2 (\\alpha - 1) + \\sigma_{XY} (-2 \\alpha + 1)\n",
    "\\\\\n",
    "0 = (\\sigma_X^2 + \\sigma_Y^2 - 2 \\sigma_{XY}) \\alpha - \\sigma_Y^2 + \\sigma_{XY}\n",
    "\\\\\n",
    "\\alpha = \\frac {\\sigma_Y^2 - \\sigma_{XY}}\n",
    "               {\\sigma_X^2 + \\sigma_Y^2 - 2 \\sigma_{XY}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of n observations.\n",
    "\n",
    "**(a)** What is the probability that the first bootstrap observation is not the jth observation from the original sample? Justify your answer.\n",
    "\n",
    "$$\n",
    "\\Pr ({x_1} \\ne {x_j}|{x_1}) = \\frac{1}{n}\\sum\\nolimits_{j = 1}^n {I({x_1} \\ne {x_j})}  = \\frac{{n - 1}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** What is the probability that the second bootstrap observation is not the jth observation from the original sample?\n",
    "\n",
    ">Same as **(a)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Argue that the probability that the jth observation is not in the bootstrap sample is $(1 - 1/n)^n$.\n",
    "\n",
    "Bootstrap is sample with replacement, so each observation in the bootstrap sample has the same 1/n (independent) chance of equaling the jth observation. Applying the product rule for a total of n observations gives us $(1 - 1/n)^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d),(e),(f)** When n = 5, 100, and 10, 000, what is the probability that the jth observation is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6723199999999999, 0.6339676587267709, 0.6321389535670295]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1-((1-(1/n))**n) for n in [5, 100, 10000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)** Create a plot that displays, for each integer value of n from 1 to 100,000, the probability that the jth observation is in the bootstrap sample. Comment on what you observe.\n",
    "\n",
    ">Very quickly reaches the ~63% probability and stays there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(1, 100001)\n",
    "y = 1-((1-(1/x))**x)\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)** We will now investigate numerically the probability that a boot- strap sample of size n = 100 contains the jth observation. Here j = 4. We repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample.\n",
    "\n",
    "> returns ~63%. Very close to our theoretical probablility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 101, (100, 10000))\n",
    "np.any(x == 4, axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** We now review k-fold cross-validation.\n",
    "**(a)** Explain how k-fold cross-validation is implemented.\n",
    "**(b)** What are the advantages and disadvantages of k-fold cross-validation relative to:\n",
    "i. The validation set approach? ii. LOOCV?\n",
    "\n",
    ">In k-fold CV you randomly divide the set of observation into k groups, or folds, of approximately equal size. The first fold is treated as a validation set, and the method is fit on the remaining k-1 folds. The error rate is then computed on the observation in the held-out fold. This procedure is repeated k times; each time a different group of observations (a fold) is treated as a validation set. The process results in k estimates of the test error and k-fold CV estimate is computed by averaging these values.\n",
    "One advantage over LOOCV is computational, bc LOOCV requires fitting the method n times. This can be expensive if n is large. If k is 5 or 10 you only have to fit the method 5 or 10 times. Additionally k-fold has lower variance and higher bias than LOOCV. Therefore k-fold often give more accurate estimates of the test error than LOOCV and this has to do with the bias-variance trade-off.\n",
    "The advantages of k-fold over the validation set approach include the fact that the validation set approach can produce highly variable test error rates.  This can happen depending on precisely which obs are included in the training set and which obs are in the validation set. K-fold addresses this by having k validation sets and training sets. Additionally, since statistical methods tend to performs worse when trained on fewer obs, the validation set error rate may tend to overestimated teh test error rate. K-fold allows for k training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Suppose that we use some statistical learning method to make a prediction for the response Y for a particular value of the predictor X. Carefully describe how we might estimate the standard deviation of our prediction.\n",
    "\n",
    ">We can bootstrap estimates of Y and use those estimates to calculate standard deviation. Through enough bootstrap estimates you could approximate a mean. From there you could calculate a standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied\n",
    "\n",
    "**5.** In Chapter 4, we used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.\n",
    "\n",
    "**(a)** Fit a logistic regression model that uses `income` and `balance` to predict `default`.\n",
    "\n",
    "**(b)** Using the validation set approach, estimate the test error of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/ISLR/Default.csv', index_col=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (10000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default01</th>\n",
       "      <th>student01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income  default01  student01\n",
       "1      No      No   729.526495  44361.625074          0          0\n",
       "2      No     Yes   817.180407  12106.134700          0          1\n",
       "3      No      No  1073.549164  31767.138947          0          0\n",
       "4      No      No   529.250605  35704.493935          0          0\n",
       "5      No      No   785.655883  38463.495879          0          0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['default01'] = np.where(df['default'] == 'Yes', 1, 0)\n",
    "df['student01'] = np.where(df['student'] == 'Yes', 1, 0)\n",
    "print(\"Dataframe shape: \" + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['income','balance']].values\n",
    "y = df['default01'].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3)\n",
      "(5000, 3)\n",
      "(5000,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# split data. for this example will we use 50/50 split\n",
    "\n",
    "# to get different test/train samples adjust 'random_state'\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.61855083]\n",
      "[[1.62553817e-05 5.83500730e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "# sklearn does regularization by default so you have to have values for 'C' and 'tol'\n",
    "#  'tol' is 'tolerance for stopping criteria' (input low value)\n",
    "#  'C' is 'invers of regularization strength' (input high integer)\n",
    "\n",
    "clf = LogisticRegression(C=1e9, tol=.0000001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.intercept_)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.975\n",
      "Test error rate: 0.025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4817</td>\n",
       "      <td>101</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4841</td>\n",
       "      <td>159</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual        0    1   All\n",
       "Predicted                 \n",
       "0          4817  101  4918\n",
       "1            24   58    82\n",
       "All        4841  159  5000"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.crosstab(clf.predict(X_test), y_test, rownames=['Predicted'],\n",
    "           colnames=['Actual'], margins=True)\n",
    "\n",
    "TN = conf_matrix.iloc[0][0]\n",
    "TP = conf_matrix.iloc[1][1]\n",
    "FN = conf_matrix.iloc[0][1]\n",
    "FP = conf_matrix.iloc[1][0]\n",
    "ALL = conf_matrix.iloc[2][2]\n",
    "accuracy = (TP+TN)/ALL\n",
    "error_rate = (FP+FN)/ALL\n",
    "\n",
    "print(\"Test accuracy: \" + str(accuracy))\n",
    "print(\"Test error rate: \" + str(error_rate))\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.\n",
    "\n",
    ">Similar error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual        0    1   All\n",
      "Predicted                 \n",
      "0          4824  102  4926\n",
      "1            22   52    74\n",
      "All        4846  154  5000\n",
      "Test error rate: 0.0248\n",
      "\n",
      "Actual        0    1   All\n",
      "Predicted                 \n",
      "0          4817  110  4927\n",
      "1            14   59    73\n",
      "All        4831  169  5000\n",
      "Test error rate: 0.0248\n",
      "\n",
      "Actual        0    1   All\n",
      "Predicted                 \n",
      "0          4818  100  4918\n",
      "1            19   63    82\n",
      "All        4837  163  5000\n",
      "Test error rate: 0.0238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build 3 models with different test/train samples\n",
    "\n",
    "clf = LogisticRegression(C=1e9, tol=.0000001)\n",
    "\n",
    "for i in range(2,5):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    conf_matrix = pd.crosstab(clf.predict(X_test), y_test, rownames=['Predicted'],\n",
    "                colnames=['Actual'], margins=True)\n",
    "    TN = conf_matrix.iloc[0][0]\n",
    "    TP = conf_matrix.iloc[1][1]\n",
    "    FN = conf_matrix.iloc[0][1]\n",
    "    FP = conf_matrix.iloc[1][0]\n",
    "    ALL = conf_matrix.iloc[2][2]\n",
    "    accuracy = (TP+TN)/ALL\n",
    "    error_rate = (FP+FN)/ALL\n",
    "    print(conf_matrix)\n",
    "    print(\"Test error rate: \" + str(error_rate) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.\n",
    "\n",
    ">Pretty much same test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.4849266]\n",
      "[[ 2.84398868e-06  5.59945216e-03 -7.92877396e-01]]\n",
      "0.9756\n"
     ]
    }
   ],
   "source": [
    "X = df[['income','balance','student01']].values\n",
    "y = df['default01'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "\n",
    "clf = LogisticRegression(C=1e9, tol=.0000001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.intercept_)\n",
    "print(clf.coef_)\n",
    "print((clf.predict(X_test)==y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** We continue to consider the use of a logistic regression model to predict the probability of `default` using `income` and `balance` on the `Default` data set. In particular, we will now compute estimates for the standard errors of the `income` and `balance` logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the glm() function. Do not forget to set a random seed before beginning your analysis.\n",
    "\n",
    "**(a)** Using the summary() and glm() functions, determine the estimated standard errors for the coefficients associated with income and balance in a multiple logistic regression model that uses both predictors.\n",
    "\n",
    "**(b),(c),(d)**\n",
    "\n",
    ">The standard errors obtained from logistic regression and bootstrap method are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.30047434]\n",
      "[[2.46453648e-05 5.48440274e-03]]\n"
     ]
    }
   ],
   "source": [
    "X = df[['income','balance']].values\n",
    "y = df['default01'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "\n",
    "clf = LogisticRegression(C=1e9, tol=.0000001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.intercept_)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>default01</td>    <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 30 Oct 2018</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>14:09:24</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              default01   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Tue, 30 Oct 2018   Pseudo R-squ.:                  0.4594\n",
       "Time:                        14:09:24   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statsmodel\n",
    "glm = smf.logit('default01 ~ income+balance', data=df).fit()\n",
    "glm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap models\n",
    "\n",
    "df_params = pd.DataFrame(columns=['Intercept', 'balance', 'income'])\n",
    "for i in range(100):\n",
    "    default_sample = df.sample(len(df), replace=True)\n",
    "    result_sample = smf.logit(formula='default01 ~ balance + income', data=default_sample).fit(disp=0)\n",
    "    df_params = df_params.append(result_sample.params, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors from bootstrap:\n",
      "Intercept    0.440460\n",
      "balance      0.000252\n",
      "income       0.000005\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard errors from bootstrap:\")\n",
    "print(df_params.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors from model:\n",
      "Intercept    0.434772\n",
      "income       0.000005\n",
      "balance      0.000227\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard errors from model:\")\n",
    "print(glm.bse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** In Sections 5.3.2 and 5.3.3, we saw that the cv.glm() function can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just the glm() and predict.glm() functions, and a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the Weekly data set. Recall that in the context of classification problems, the LOOCV error is given in (5.4).\n",
    "\n",
    "**(a)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/Weekly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (1089, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Direction01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction  \\\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down   \n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down   \n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up   \n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up   \n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up   \n",
       "\n",
       "   Direction01  \n",
       "0            0  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert 'Direction' from 'Yes/No' to 0/1. For ease in modeling.\n",
    "df['Direction01'] = np.where(df['Direction'] == 'Up', 1, 0)\n",
    "print(\"Shape of dataframe: \" + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Lag1','Lag2']]\n",
    "y = df['Direction01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22122405]\n",
      "[[-0.03872222  0.0602483 ]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1e9, tol=.0000001)\n",
    "clf.fit(X,y)\n",
    "\n",
    "print(clf.intercept_)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Fit a logistic regression model that predicts `Direction` using `Lag1` and `Lag2` using all but the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22324305]\n",
      "[[-0.03843317  0.06084763]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X.iloc[1:],y[1:])\n",
    "\n",
    "print(clf.intercept_)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Use the model from (b) to predict the direction of the first observation.\n",
    "\n",
    ">Misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability 0/1:\n",
      "[[0.42860768 0.57139232]]\n",
      "Predicted outcome 0=down, 1=up:\n",
      "[1]\n",
      "Actual outcome:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted probability 0/1:\")\n",
    "print(clf.predict_proba(X.iloc[:1]))\n",
    "print(\"Predicted outcome 0=down, 1=up:\")\n",
    "print(clf.predict(X.iloc[:1]))\n",
    "print(\"Actual outcome:\")\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Write a for loop from i=1 to i=n,where n is the number of observations in the data set. Fit a logistic regression model using all but the ith observation to predict Direction using Lag1 and Lag2. Compute the posterior probability of the market moving up for the ith observation. Use the posterior probability for the ith observation in order to predict whether or not the market moves up. Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.\n",
    "\n",
    "**(e)** Take the average of the n numbers obtained in (d) in order to obtain the LOOCV estimate for the test error. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(len(X))\n",
    "for i in range(len(X)):\n",
    "    leave_out = ~X.index.isin([i])\n",
    "    clf.fit(X[leave_out], y[leave_out])\n",
    "    if clf.predict([X.iloc[i]]) != y[i]:\n",
    "        errors[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44995408631772266"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** We will now perform cross-validation on a simulated data set.\n",
    "(a) Generate a simulated data set. In this data set, what is n and what is p? Write out the model used to generate the data in equation form.\n",
    "\n",
    "n=100, p=2\n",
    "\n",
    "$Y = X - 2 X^2 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "y = np.random.randn(100)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "\n",
    "y = x-2*x**2+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Set a random seed, and then compute the LOOCV errors that result from fitting four models using least squares.\n",
    "\n",
    "**(d),(e),(f)**\n",
    "\n",
    ">Since our true data is quadratic, the quadratic model has the lowest LOOCV error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>x</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.447129</td>\n",
       "      <td>0.199924</td>\n",
       "      <td>-0.089392</td>\n",
       "      <td>0.039970</td>\n",
       "      <td>-1.247855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.224508</td>\n",
       "      <td>1.499419</td>\n",
       "      <td>1.836050</td>\n",
       "      <td>2.248258</td>\n",
       "      <td>-0.950325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403492</td>\n",
       "      <td>0.162806</td>\n",
       "      <td>0.065691</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>-0.484425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.593579</td>\n",
       "      <td>0.352335</td>\n",
       "      <td>0.209139</td>\n",
       "      <td>0.124140</td>\n",
       "      <td>1.843786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.094912</td>\n",
       "      <td>1.198832</td>\n",
       "      <td>-1.312615</td>\n",
       "      <td>1.437198</td>\n",
       "      <td>-4.824527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    b0         x        x2        x3        x4         y\n",
       "0  1.0 -0.447129  0.199924 -0.089392  0.039970 -1.247855\n",
       "1  1.0  1.224508  1.499419  1.836050  2.248258 -0.950325\n",
       "2  1.0  0.403492  0.162806  0.065691  0.026506 -0.484425\n",
       "3  1.0  0.593579  0.352335  0.209139  0.124140  1.843786\n",
       "4  1.0 -1.094912  1.198832 -1.312615  1.437198 -4.824527"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array([np.ones(len(x)), x, x**2, x**3, x**4, y]).T, \\\n",
    "                 columns=['b0', 'x', 'x2', 'x3', 'x4', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :5] # all the rows and the first 5 columns\n",
    "y = df['y']\n",
    "\n",
    "errors = np.zeros((len(X), 4))\n",
    "clf = LinearRegression()\n",
    "for i in range(len(X)):\n",
    "    leave_out = ~X.index.isin([i])\n",
    "    for j in range(4):\n",
    "        clf.fit(X.iloc[leave_out, :j+2], y[leave_out])\n",
    "        errors[i,j] = (clf.predict([X.iloc[i, :j+2]]) - y[i]) **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.29221162, 1.01709581, 1.04655346, 1.05749267])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** We will now consider the Boston housing data set, from the MASS library.\n",
    "\n",
    "**(a)** Based on this data set, provide an estimate for the population mean of medv. Call this estimate Î¼Ë."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe: (506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv').dropna()\n",
    "print(\"Shape of dataframe: \" + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           medv\n",
       "mean  22.532806"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc[['mean'],['medv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110677"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to get mean of 'medv'\n",
    "df['medv'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Provide an estimate of the standard error of Î¼Ë. Interpret this result. _Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40886114749753505"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['medv'].std()/(np.sqrt(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Now estimate the standard error of Î¼Ë using the bootstrap. How does this compare to your answer from (b)?\n",
    "\n",
    ">Very close to (b). 0.408 vs 0.393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.867786561264822"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to sample 'medv' from df. (uses pd.df.sample)\n",
    "# can keep running this cell to get more samples\n",
    "# you can select random_state=(int) to select a seed\n",
    "df['medv'].sample(n=len(df), replace=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39338181607359535"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bootstrap our sampling from above. let's do it 1000 times\n",
    "means = [df['medv'].sample(n=len(df), replace=True).mean() for i in range(1000)]\n",
    "np.std(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained using t.test(Boston$medv).\n",
    "\n",
    "_Hint: You can approximate a 95% confidence interval using the formula [Î¼Ë â 2SE(Î¼Ë), Î¼Ë + 2SE(Î¼Ë)]._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.750394075362692, 23.323921339657076)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(means)\n",
    "std = np.std(means)\n",
    "\n",
    "mean-2*std, mean+2*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=54.1490054595382, pvalue=1.8902409332198788e-212)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one sample t-test\n",
    "stats.ttest_1samp(df['medv'], std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.766143515832677, 23.30817189918709)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% conf interval\n",
    "stats.norm.interval(0.95, loc=mean, scale=std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Based on this data set, provide an estimate, Î¼Ëmed, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['medv'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** We now would like to estimate the standard error of Î¼Ëmed. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings.\n",
    "\n",
    ">Small SE for median. 20.9 v 0.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.9"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to (c)\n",
    "df['medv'].sample(n=len(df), replace=True).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3875551573647289"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meds = [df['medv'].sample(n=len(df), replace=True).median() for i in range(1000)]\n",
    "np.std(meds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)** Based on this data set, provide an estimate for the tenth percentile of medv in Boston suburbs. Call this quantity Î¼Ë0.1. (You can use the quantile() function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pandas 'quantile' api\n",
    "df['medv'].quantile(q=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)** Use the bootstrap to estimate the standard error of Î¼Ë0.1. Comment on your findings.\n",
    "\n",
    "Remember: MEDV - Median value of owner-occupied homes in $1000's\n",
    "\n",
    ">Larger relative SE for the tenth percentile that the whole market. There is more price fluctuation at the bottom end of the market relative to the whole market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.502668814926886"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_1 = [df['medv'].sample(n=len(df), replace=True).quantile(q=0.1) for i in range(1000)]\n",
    "np.std(q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             medv\n",
       "count  506.000000\n",
       "mean    22.532806\n",
       "std      9.197104\n",
       "min      5.000000\n",
       "25%     17.025000\n",
       "50%     21.200000\n",
       "75%     25.000000\n",
       "max     50.000000"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().loc[:,['medv']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
